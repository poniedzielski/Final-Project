{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application for Audiobooks Company to predict clients behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction whether the customer will buy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "There is data from the Audiobook App in which each customer in the database has made a purchase at least once, that is why we have it's data.\n",
    "\n",
    "Data was collected for 2.5 years. Data for the first 2 year has been used for preparation the targets column and was caluclated by assign boolean 0 or 1 to each customer depending on that if each one of them has bought another product again for the next 6 months of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to make an algorithm which can predict if a customer will buy again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a solution approach will be used the model with deep neural network using __TensorFlow__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intuition is that if customers have a low probability of coming back, there is no reason to spend any money on theirs advertising.  \n",
    "\n",
    "The orginal csv file with data contains a few variables that describe customers and theirs behaviours:\n",
    "1. Customer ID, \n",
    "2. Book length average (average length in minutes of all purchases), \n",
    "3. Book length overall (sum of the minute length of all purchases), \n",
    "5. Price paid average (average of all purchases), \n",
    "4. Price paid overall (sum of all purchases),\n",
    "6. Review (a boolean variable whether the customer left a review), \n",
    "7. Review [from 0 to 10] (if the customer left a review, his/her review out of 10), \n",
    "8. Percent of completion [from 0 to 1],\n",
    "9. Total minutes of listening,  \n",
    "10. Support requests (number of support requests; everything from forgotten password to assistance for using the app), \n",
    "11. Last visited since purchase date (in days).\n",
    "\n",
    "First column of dataset which cointains Customer ID has to be dropped in algorithm and the last column refers to targets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (14084, 12)\n",
      "\n",
      "Sample of observations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>len_avg</th>\n",
       "      <th>len_overall</th>\n",
       "      <th>price_avg</th>\n",
       "      <th>price_overall</th>\n",
       "      <th>if_review</th>\n",
       "      <th>review</th>\n",
       "      <th>completion</th>\n",
       "      <th>total_listen</th>\n",
       "      <th>support_req</th>\n",
       "      <th>last_visit_since_purchase</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>27824</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>6048</td>\n",
       "      <td>5.33</td>\n",
       "      <td>21.33</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1143</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2059</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>23200</td>\n",
       "      <td>648.0</td>\n",
       "      <td>648</td>\n",
       "      <td>10.13</td>\n",
       "      <td>10.13</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>168.48</td>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2882</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>5.96</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.42</td>\n",
       "      <td>680.40</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  len_avg  len_overall  price_avg  price_overall  if_review  review  \\\n",
       "80  27824   1512.0         6048       5.33          21.33          0     NaN   \n",
       "81   1143   2160.0         2160       5.33           5.33          0     NaN   \n",
       "82   2059   2160.0         2160       5.33           5.33          0     NaN   \n",
       "83  23200    648.0          648      10.13          10.13          1     9.0   \n",
       "84   2882   1620.0         1620       5.96           5.96          0     NaN   \n",
       "\n",
       "    completion  total_listen  support_req  last_visit_since_purchase  targets  \n",
       "80        0.00          0.00            0                          0        1  \n",
       "81        0.00          0.00            0                          0        0  \n",
       "82        0.00          0.00            0                        388        0  \n",
       "83        0.26        168.48            0                        337        0  \n",
       "84        0.42        680.40            1                        129        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data for a view and statistics\n",
    "columns=['ID','len_avg','len_overall','price_avg','price_overall','if_review','review','completion','total_listen','support_req','last_visit_since_purchase','targets']\n",
    "path = 'D:\\\\Dokumenty\\\\Piotr\\\\PROJEKTY\\\\audiobook shop\\\\audiobooks_data_new.csv'\n",
    "\n",
    "raw_data = pd.read_csv(path,delimiter=',',header=None,names=columns)\n",
    "\n",
    "print(\"Data shape: {0}\".format(raw_data.shape))\n",
    "print('\\nSample of observations:')\n",
    "raw_data[80:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>len_avg</th>\n",
       "      <th>len_overall</th>\n",
       "      <th>price_avg</th>\n",
       "      <th>price_overall</th>\n",
       "      <th>if_review</th>\n",
       "      <th>review</th>\n",
       "      <th>completion</th>\n",
       "      <th>total_listen</th>\n",
       "      <th>support_req</th>\n",
       "      <th>last_visit_since_purchase</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>2467.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16772.491551</td>\n",
       "      <td>1591.281685</td>\n",
       "      <td>1678.608634</td>\n",
       "      <td>7.103791</td>\n",
       "      <td>7.543805</td>\n",
       "      <td>0.175163</td>\n",
       "      <td>8.908926</td>\n",
       "      <td>0.125659</td>\n",
       "      <td>189.888983</td>\n",
       "      <td>0.070222</td>\n",
       "      <td>61.935033</td>\n",
       "      <td>0.158833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9691.807248</td>\n",
       "      <td>504.340663</td>\n",
       "      <td>654.838599</td>\n",
       "      <td>4.931673</td>\n",
       "      <td>5.560129</td>\n",
       "      <td>0.380120</td>\n",
       "      <td>1.537566</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>371.084010</td>\n",
       "      <td>0.472157</td>\n",
       "      <td>88.207634</td>\n",
       "      <td>0.365533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8368.000000</td>\n",
       "      <td>1188.000000</td>\n",
       "      <td>1188.000000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16711.500000</td>\n",
       "      <td>1620.000000</td>\n",
       "      <td>1620.000000</td>\n",
       "      <td>5.950000</td>\n",
       "      <td>6.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25187.250000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33683.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>130.940000</td>\n",
       "      <td>130.940000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID       len_avg   len_overall     price_avg  price_overall  \\\n",
       "count  14084.000000  14084.000000  14084.000000  14084.000000   14084.000000   \n",
       "mean   16772.491551   1591.281685   1678.608634      7.103791       7.543805   \n",
       "std     9691.807248    504.340663    654.838599      4.931673       5.560129   \n",
       "min        2.000000    216.000000    216.000000      3.860000       3.860000   \n",
       "25%     8368.000000   1188.000000   1188.000000      5.330000       5.330000   \n",
       "50%    16711.500000   1620.000000   1620.000000      5.950000       6.070000   \n",
       "75%    25187.250000   2160.000000   2160.000000      8.000000       8.000000   \n",
       "max    33683.000000   2160.000000   7020.000000    130.940000     130.940000   \n",
       "\n",
       "          if_review       review    completion  total_listen   support_req  \\\n",
       "count  14084.000000  2467.000000  14084.000000  14084.000000  14084.000000   \n",
       "mean       0.175163     8.908926      0.125659    189.888983      0.070222   \n",
       "std        0.380120     1.537566      0.241206    371.084010      0.472157   \n",
       "min        0.000000     1.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000     8.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000    10.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000    10.000000      0.130000    194.400000      0.000000   \n",
       "max        1.000000    10.000000      1.000000   2160.000000     30.000000   \n",
       "\n",
       "       last_visit_since_purchase       targets  \n",
       "count               14084.000000  14084.000000  \n",
       "mean                   61.935033      0.158833  \n",
       "std                    88.207634      0.365533  \n",
       "min                     0.000000      0.000000  \n",
       "25%                     0.000000      0.000000  \n",
       "50%                    11.000000      0.000000  \n",
       "75%                   105.000000      0.000000  \n",
       "max                   464.000000      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14084 entries, 0 to 14083\n",
      "Data columns (total 12 columns):\n",
      "ID                           14084 non-null int64\n",
      "len_avg                      14084 non-null float64\n",
      "len_overall                  14084 non-null int64\n",
      "price_avg                    14084 non-null float64\n",
      "price_overall                14084 non-null float64\n",
      "if_review                    14084 non-null int64\n",
      "review                       2467 non-null float64\n",
      "completion                   14084 non-null float64\n",
      "total_listen                 14084 non-null float64\n",
      "support_req                  14084 non-null int64\n",
      "last_visit_since_purchase    14084 non-null int64\n",
      "targets                      14084 non-null int64\n",
      "dtypes: float64(6), int64(6)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that in one column 'review' there are missing values and they are in the majority. The solution for that problem might be replacing those missing values by an average for these ones that exist. Another approach could be removing this column. There are also algorithms like LightGBM that can handle unbalanced inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An avergae of exisiting reviews: 8.909\n"
     ]
    }
   ],
   "source": [
    "#Amount of reviews\n",
    "reviews_count = np.sum(raw_data['if_review'])\n",
    "#Sum of all reviews\n",
    "reviews_sum = np.sum(raw_data['review'])\n",
    "#Avarage of reviews\n",
    "reviews_avg = np.round(reviews_sum / reviews_count,3)\n",
    "print('An avergae of exisiting reviews: {0}'.format(reviews_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data['review'].fillna(value=reviews_avg,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>len_avg</th>\n",
       "      <th>len_overall</th>\n",
       "      <th>price_avg</th>\n",
       "      <th>price_overall</th>\n",
       "      <th>if_review</th>\n",
       "      <th>review</th>\n",
       "      <th>completion</th>\n",
       "      <th>total_listen</th>\n",
       "      <th>support_req</th>\n",
       "      <th>last_visit_since_purchase</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>27824</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>6048</td>\n",
       "      <td>5.33</td>\n",
       "      <td>21.33</td>\n",
       "      <td>0</td>\n",
       "      <td>8.909</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1143</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>8.909</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2059</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>8.909</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>23200</td>\n",
       "      <td>648.0</td>\n",
       "      <td>648</td>\n",
       "      <td>10.13</td>\n",
       "      <td>10.13</td>\n",
       "      <td>1</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.26</td>\n",
       "      <td>168.48</td>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2882</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>5.96</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0</td>\n",
       "      <td>8.909</td>\n",
       "      <td>0.42</td>\n",
       "      <td>680.40</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3342</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>8.909</td>\n",
       "      <td>0.22</td>\n",
       "      <td>475.20</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3416</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>4.61</td>\n",
       "      <td>4.61</td>\n",
       "      <td>0</td>\n",
       "      <td>8.909</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>31759</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>4949</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>8.909</td>\n",
       "      <td>0.04</td>\n",
       "      <td>86.40</td>\n",
       "      <td>0</td>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>9011</td>\n",
       "      <td>648.0</td>\n",
       "      <td>648</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>8.909</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  len_avg  len_overall  price_avg  price_overall  if_review  review  \\\n",
       "80  27824   1512.0         6048       5.33          21.33          0   8.909   \n",
       "81   1143   2160.0         2160       5.33           5.33          0   8.909   \n",
       "82   2059   2160.0         2160       5.33           5.33          0   8.909   \n",
       "83  23200    648.0          648      10.13          10.13          1   9.000   \n",
       "84   2882   1620.0         1620       5.96           5.96          0   8.909   \n",
       "85   3342   2160.0         2160       5.33           5.33          0   8.909   \n",
       "86   3416   2160.0         2160       4.61           4.61          0   8.909   \n",
       "87  31759   2160.0         2160       5.33           5.33          1  10.000   \n",
       "88   4949   2160.0         2160       5.33           5.33          0   8.909   \n",
       "89   9011    648.0          648       5.33           5.33          0   8.909   \n",
       "\n",
       "    completion  total_listen  support_req  last_visit_since_purchase  targets  \n",
       "80        0.00          0.00            0                          0        1  \n",
       "81        0.00          0.00            0                          0        0  \n",
       "82        0.00          0.00            0                        388        0  \n",
       "83        0.26        168.48            0                        337        0  \n",
       "84        0.42        680.40            1                        129        0  \n",
       "85        0.22        475.20            0                        361        0  \n",
       "86        0.00          0.00            0                          0        0  \n",
       "87        0.00          0.00            0                        294        1  \n",
       "88        0.04         86.40            0                        366        0  \n",
       "89        0.00          0.00            0                          0        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[80:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An average of reviews after replacement missing values: 8.909\n"
     ]
    }
   ],
   "source": [
    "#Check the average again for all review values\n",
    "reviews_avg = np.round(np.mean(raw_data['review']),3)\n",
    "print('An average of reviews after replacement missing values: {0}'.format(reviews_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#As an option - removing certain columns to check if this helps to improve the algorithm\n",
    "#raw_data = raw_data.drop('review',axis=1)\n",
    "#raw_data = raw_data.drop('if_review',axis=1)\n",
    "#raw_data = raw_data.drop('support_req',axis=1)\n",
    "#raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of variables without ID: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>len_avg</th>\n",
       "      <th>len_overall</th>\n",
       "      <th>price_avg</th>\n",
       "      <th>price_overall</th>\n",
       "      <th>if_review</th>\n",
       "      <th>review</th>\n",
       "      <th>completion</th>\n",
       "      <th>total_listen</th>\n",
       "      <th>support_req</th>\n",
       "      <th>engagement</th>\n",
       "      <th>last_visit_since_purchase</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>994</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>19.73</td>\n",
       "      <td>19.73</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1603.8</td>\n",
       "      <td>5</td>\n",
       "      <td>91.08</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29480</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21785</td>\n",
       "      <td>324.0</td>\n",
       "      <td>324</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16978</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>2808</td>\n",
       "      <td>6.67</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14642</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>1188</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  len_avg  len_overall  price_avg  price_overall  if_review  review  \\\n",
       "0    994   1620.0         1620      19.73          19.73          1    10.0   \n",
       "1  29480   1620.0         1620       5.33           5.33          1     2.0   \n",
       "2  21785    324.0          324       5.33           5.33          1     2.0   \n",
       "3  16978   1404.0         2808       6.67          13.33          1     3.0   \n",
       "4  14642   1188.0         1188       5.33           5.33          1     4.0   \n",
       "\n",
       "   completion  total_listen  support_req  engagement  \\\n",
       "0        0.99        1603.8            5       91.08   \n",
       "1        0.00           0.0            0        0.00   \n",
       "2        0.00           0.0            0        0.00   \n",
       "3        0.00           0.0            1        0.00   \n",
       "4        0.00           0.0            0        0.00   \n",
       "\n",
       "   last_visit_since_purchase  targets  \n",
       "0                         92        0  \n",
       "1                        145        1  \n",
       "2                          0        1  \n",
       "3                        176        1  \n",
       "4                        255        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As an option -  Feature engineering\n",
    "#raw_data.insert(loc=3,column='books quantity', value=raw_data['len_overall']/raw_data['len_avg'])\n",
    "#raw_data.insert(loc=6,column='avg_price/len_avg', value=raw_data['price_avg']/raw_data['len_avg'])\n",
    "raw_data.insert(loc=10,column='engagement',value=raw_data['completion']*raw_data['last_visit_since_purchase'])\n",
    "print(\"Quantity of variables without ID: {0}\".format(raw_data.shape[1]-2))\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to csv for further operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save raw data to csv file \n",
    "raw_data.to_csv('raw_data.csv',index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9400e+02, 1.6200e+03, 1.6200e+03, 1.9730e+01, 1.9730e+01,\n",
       "       1.0000e+00, 1.0000e+01, 9.9000e-01, 1.6038e+03, 5.0000e+00,\n",
       "       9.1080e+01, 9.2000e+01, 0.0000e+00])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2= 'raw_data.csv'\n",
    "\n",
    "#Load data to numpy format\n",
    "raw_csv_data = np.loadtxt(path2,delimiter=\",\")\n",
    "raw_csv_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of clients who has bought again in 6 months after data has been collected: 15.883%\n"
     ]
    }
   ],
   "source": [
    "#Raw inputs / the first column are IDs and the last column includes targets, need to drop these ones for getting inputs\n",
    "raw_inputs = raw_csv_data[:,1:-1]\n",
    "#Raw targets / last column\n",
    "raw_targets = raw_csv_data[:,-1]\n",
    "\n",
    "print('Percent of clients who has bought again in 6 months after data has been collected: {0}'.format(100*np.round(np.sum(raw_targets)/len(raw_targets),5))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffled data\n",
    "Before balancing to avoid situation when there are around 2300 targets that are 1s in full range of data collection time (2 years) but only a few months contain the same number of 0s targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seed\n",
    "np.random.seed(123)\n",
    "#Shuffle indieces\n",
    "shuffled_indices = np.arange(raw_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "#Shuffle inputs and targets using shuffled indieces\n",
    "raw_shuffled_inputs = raw_inputs[shuffled_indices]\n",
    "raw_shuffled_targets = raw_targets[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance tha data set\n",
    "For keeping as many 0s as 1s targets, remove those more numerous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observation to remove: 9610\n"
     ]
    }
   ],
   "source": [
    "#Number of customers who have bought again in 6 months after the data was final collected\n",
    "num_one_targets = int(np.sum(raw_shuffled_targets))\n",
    "#Counter of customers who have not bought\n",
    "zero_targets_counter = 0\n",
    "#List for collecting indices for observation that will be removed\n",
    "indices_to_remove = []\n",
    "\n",
    "#Collect indices of targets 0 when the number of zeros and ones reach the equilibrium\n",
    "for i in range(raw_targets.shape[0]):\n",
    "    if raw_targets[i] == 0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "\n",
    "print(\"Number of observation to remove: {0}\".format(len(indices_to_remove)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs size:  4474 \n",
      "Targets size: 4474\n"
     ]
    }
   ],
   "source": [
    "#Balance inputs and targets by removing additional observations\n",
    "balanced_inputs = np.delete(raw_inputs, indices_to_remove, axis=0)\n",
    "balanced_targets = np.delete(raw_targets, indices_to_remove, axis=0)\n",
    "\n",
    "print(\"Inputs size: \", len(balanced_inputs),\n",
    "      \"\\nTargets size:\", len(balanced_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Center to the mean and component wise scale to unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_inputs = preprocessing.scale(balanced_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the data again\n",
    "Train, validation, and test have to be balanced by themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seed\n",
    "np.random.seed(12345)\n",
    "#Shuffle indieces again\n",
    "shuffled_indices = np.arange(std_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "#Use the shuffled indices to shuffle the inputs and targets.\n",
    "shuffled_inputs = std_inputs[shuffled_indices]\n",
    "shuffled_targets = balanced_targets[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train, validation and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of observations: 4474 \n",
      "\n",
      "train size:      3579 \n",
      "validation size: 447 \n",
      "test size:       448 \n",
      "\n",
      "      targets  samples  balance\n",
      "train 1789.0   3579     0.49986\n",
      "valid 222.0    447      0.49664\n",
      "test  226.0    448      0.50446\n"
     ]
    }
   ],
   "source": [
    "#Total number of samples\n",
    "total_samples_count= shuffled_inputs.shape[0]\n",
    "print(\"total number of observations: {0}\".format(total_samples_count),\"\\n\")\n",
    "\n",
    "#Number of each subset (80% training, 10% validation, 10% test sets)\n",
    "train_samples_count = int(0.80*total_samples_count)\n",
    "valid_samples_count = int(0.1*total_samples_count)\n",
    "test_samples_count = total_samples_count - train_samples_count - valid_samples_count\n",
    "\n",
    "print(\"train size:      {0}\".format(train_samples_count), \n",
    "      \"\\nvalidation size: {0}\".format(valid_samples_count),\n",
    "      \"\\ntest size:       {0}\".format(test_samples_count),\"\\n\")\n",
    "\n",
    "#Create:\n",
    "#Training sets\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "#Validation sets\n",
    "valid_inputs = shuffled_inputs[train_samples_count:train_samples_count+valid_samples_count]\n",
    "valid_targets = shuffled_targets[train_samples_count:train_samples_count+valid_samples_count]\n",
    "\n",
    "#Test sets\n",
    "test_inputs = shuffled_inputs[train_samples_count+valid_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count+valid_samples_count:]\n",
    "\n",
    "#Check if balance is in approximation 50%\n",
    "print(\"     \",\"targets\",\" samples\", \" balance\")\n",
    "print(\"train\",np.sum(train_targets),\" \", train_samples_count,\"   \", np.round(np.sum(train_targets) / train_samples_count,decimals=5))\n",
    "print(\"valid\",np.sum(valid_targets),\"  \", valid_samples_count, \"    \",np.round(np.sum(valid_targets) / valid_samples_count,decimals=5))\n",
    "print(\"test \",np.sum(test_targets),\"  \", test_samples_count, \"    \",np.round(np.sum(test_targets) / test_samples_count, decimals=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Save training, valiation and test sets as npz file for Tensorflow usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('audiobooks_data_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('audiobooks_data_valid', inputs=valid_inputs, targets=valid_targets)\n",
    "np.savez('audiobooks_data_test', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AudiobooksDataReader():\n",
    "    \n",
    "    \"\"\"\n",
    "    Class that will do the batching for the algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, batch_size = None):\n",
    "        \n",
    "        #Load subset of the data, one from: \"train\", \"validation\" or \"test\" \n",
    "        npz = np.load('audiobooks_data_{0}.npz'.format(dataset))\n",
    "        \n",
    "        #Create variables of inputs and outputs for given subsets of data\n",
    "        self.inputs, self.targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "        \n",
    "        #Save the number of batch size\n",
    "        #If the batch size is None, it's validation or testing, so the data is in a single batch        \n",
    "        if batch_size is None: \n",
    "            self.batch_size = self.inputs.shape[0]\n",
    "        else:\n",
    "            self.batch_size = batch_size\n",
    "            \n",
    "        #Set the counter for batches starting from 0\n",
    "        self.curr_batch = 0\n",
    "        \n",
    "        #Calculate the number of batches\n",
    "        self.batch_count = self.inputs.shape[0] // self.batch_size\n",
    "    \n",
    "    #Load the next batch\n",
    "    def __next__(self):\n",
    "        if self.curr_batch >= self.batch_count:\n",
    "            self.curr_batch = 0\n",
    "            raise StopIteration()\n",
    "            \n",
    "        #Slicing the dataset in batches and then loading them one after the other\n",
    "        batch_slice = slice(self.curr_batch * self.batch_size, \\\n",
    "                           (self.curr_batch + 1) * self.batch_size)\n",
    "        inputs_batch = self.inputs[batch_slice]\n",
    "        targets_batch = self.targets[batch_slice]\n",
    "        self.curr_batch += 1\n",
    "        \n",
    "        #One-hot encode the targets. Optional task in binary classification\n",
    "        classes_num = 2\n",
    "        targets_one_hot = np.zeros((targets_batch.shape[0], classes_num))\n",
    "        targets_one_hot[range(targets_batch.shape[0]), targets_batch] = 1\n",
    "        \n",
    "        #Return the inputs batch and the one-hot encoded targets\n",
    "        return inputs_batch, targets_one_hot\n",
    "    \n",
    "        \n",
    "    #Iterating over the batches,\n",
    "    def __iter__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learining Model with TensorFlow\n",
    "### Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seed\n",
    "tf.set_random_seed(123)\n",
    "#Input size depends on the number of input variables\n",
    "input_size = 11\n",
    "#Output size of binary classification\n",
    "output_size = 2\n",
    "#Hidden layer size\n",
    "hidden_layer_size = 50\n",
    "#Set the batch size\n",
    "batch_size = 100\n",
    "#Set learing rate\n",
    "l_rate = 0.0005\n",
    "#Set early stopping mechanisms\n",
    "max_epochs = 1000\n",
    "prev_validation_loss = 9999999.\n",
    "\n",
    "\n",
    "#Reset the default graph, in case of reuse \n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "#Create placeholders\n",
    "inputs = tf.placeholder(tf.float32, [None, input_size])\n",
    "targets = tf.placeholder(tf.int32, [None, output_size])\n",
    "\n",
    "#Parameters and operations of the model\n",
    "weights_1 = tf.get_variable(\"weights_1\", [input_size, hidden_layer_size])\n",
    "biases_1 = tf.get_variable(\"biases_1\", [hidden_layer_size])\n",
    "outputs_1 = tf.nn.relu(tf.matmul(inputs, weights_1) + biases_1)\n",
    "\n",
    "weights_2 = tf.get_variable(\"weights_2\", [hidden_layer_size, hidden_layer_size])\n",
    "biases_2 = tf.get_variable(\"biases_2\", [hidden_layer_size])\n",
    "outputs_2 = tf.nn.sigmoid(tf.matmul(outputs_1, weights_2) + biases_2)\n",
    "\n",
    "weights_3 = tf.get_variable(\"weights_3\", [hidden_layer_size, output_size])\n",
    "biases_3 = tf.get_variable(\"biases_3\", [output_size])\n",
    "\n",
    "#In this case no usage of activation function as it is use in loss below\n",
    "outputs = tf.matmul(outputs_2, weights_3) + biases_3\n",
    "\n",
    "#Use the softmax cross entropy loss with logits\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=outputs, labels=targets)\n",
    "mean_loss = tf.reduce_mean(loss)\n",
    "\n",
    "#Get a 0 or 1 for every input indicating if an output is the correct answer\n",
    "out_equals_target = tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1))\n",
    "\n",
    "#accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(out_equals_target, tf.float32))\n",
    "\n",
    "#Optimize with ADAM / ADAptive Moment estimator - include RMSProp and Momentum /\n",
    "optimize = tf.train.AdamOptimizer(learning_rate=l_rate).minimize(mean_loss)\n",
    "\n",
    "#Start a tensorflow session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#Initialize the variables\n",
    "initializer = tf.global_variables_initializer()\n",
    "sess.run(initializer)\n",
    "\n",
    "#Load the first batch of training and validation\n",
    "train_data = AudiobooksDataReader('train', batch_size)\n",
    "validation_data = AudiobooksDataReader('valid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Training loss: 0.639. Validation loss: 0.613. Validation accuracy: 64.43%\n",
      "Epoch 2. Training loss: 0.566. Validation loss: 0.557. Validation accuracy: 76.29%\n",
      "Epoch 3. Training loss: 0.516. Validation loss: 0.511. Validation accuracy: 76.73%\n",
      "Epoch 4. Training loss: 0.477. Validation loss: 0.477. Validation accuracy: 77.18%\n",
      "Epoch 5. Training loss: 0.448. Validation loss: 0.452. Validation accuracy: 76.96%\n",
      "Epoch 6. Training loss: 0.426. Validation loss: 0.435. Validation accuracy: 78.52%\n",
      "Epoch 7. Training loss: 0.411. Validation loss: 0.423. Validation accuracy: 77.40%\n",
      "Epoch 8. Training loss: 0.399. Validation loss: 0.413. Validation accuracy: 77.63%\n",
      "Epoch 9. Training loss: 0.390. Validation loss: 0.405. Validation accuracy: 77.63%\n",
      "Epoch 10. Training loss: 0.382. Validation loss: 0.399. Validation accuracy: 77.85%\n",
      "Epoch 11. Training loss: 0.376. Validation loss: 0.393. Validation accuracy: 78.52%\n",
      "Epoch 12. Training loss: 0.370. Validation loss: 0.388. Validation accuracy: 79.42%\n",
      "Epoch 13. Training loss: 0.366. Validation loss: 0.385. Validation accuracy: 80.54%\n",
      "Epoch 14. Training loss: 0.362. Validation loss: 0.381. Validation accuracy: 80.98%\n",
      "Epoch 15. Training loss: 0.358. Validation loss: 0.378. Validation accuracy: 80.98%\n",
      "Epoch 16. Training loss: 0.355. Validation loss: 0.376. Validation accuracy: 80.98%\n",
      "Epoch 17. Training loss: 0.353. Validation loss: 0.374. Validation accuracy: 80.98%\n",
      "Epoch 18. Training loss: 0.350. Validation loss: 0.372. Validation accuracy: 81.21%\n",
      "Epoch 19. Training loss: 0.348. Validation loss: 0.370. Validation accuracy: 81.43%\n",
      "Epoch 20. Training loss: 0.346. Validation loss: 0.369. Validation accuracy: 80.98%\n",
      "Epoch 21. Training loss: 0.344. Validation loss: 0.367. Validation accuracy: 80.98%\n",
      "Epoch 22. Training loss: 0.342. Validation loss: 0.366. Validation accuracy: 81.21%\n",
      "Epoch 23. Training loss: 0.341. Validation loss: 0.365. Validation accuracy: 81.21%\n",
      "Epoch 24. Training loss: 0.339. Validation loss: 0.364. Validation accuracy: 81.21%\n",
      "Epoch 25. Training loss: 0.338. Validation loss: 0.363. Validation accuracy: 81.43%\n",
      "Epoch 26. Training loss: 0.337. Validation loss: 0.362. Validation accuracy: 81.21%\n",
      "Epoch 27. Training loss: 0.335. Validation loss: 0.361. Validation accuracy: 81.21%\n",
      "Epoch 28. Training loss: 0.334. Validation loss: 0.360. Validation accuracy: 81.21%\n",
      "Epoch 29. Training loss: 0.333. Validation loss: 0.360. Validation accuracy: 80.76%\n",
      "Epoch 30. Training loss: 0.332. Validation loss: 0.359. Validation accuracy: 81.21%\n",
      "Epoch 31. Training loss: 0.331. Validation loss: 0.359. Validation accuracy: 81.21%\n",
      "Epoch 32. Training loss: 0.331. Validation loss: 0.358. Validation accuracy: 81.21%\n",
      "Epoch 33. Training loss: 0.330. Validation loss: 0.358. Validation accuracy: 80.76%\n",
      "Epoch 34. Training loss: 0.329. Validation loss: 0.357. Validation accuracy: 80.98%\n",
      "Epoch 35. Training loss: 0.328. Validation loss: 0.357. Validation accuracy: 81.21%\n",
      "Epoch 36. Training loss: 0.328. Validation loss: 0.357. Validation accuracy: 80.98%\n",
      "Epoch 37. Training loss: 0.327. Validation loss: 0.357. Validation accuracy: 81.21%\n",
      "Epoch 38. Training loss: 0.326. Validation loss: 0.356. Validation accuracy: 81.21%\n",
      "Epoch 39. Training loss: 0.326. Validation loss: 0.356. Validation accuracy: 81.21%\n",
      "Epoch 40. Training loss: 0.325. Validation loss: 0.356. Validation accuracy: 81.21%\n",
      "Epoch 41. Training loss: 0.324. Validation loss: 0.355. Validation accuracy: 81.21%\n",
      "Epoch 42. Training loss: 0.324. Validation loss: 0.355. Validation accuracy: 81.21%\n",
      "Epoch 43. Training loss: 0.323. Validation loss: 0.355. Validation accuracy: 81.21%\n",
      "Epoch 44. Training loss: 0.323. Validation loss: 0.354. Validation accuracy: 81.43%\n",
      "Epoch 45. Training loss: 0.322. Validation loss: 0.354. Validation accuracy: 81.43%\n",
      "Epoch 46. Training loss: 0.322. Validation loss: 0.354. Validation accuracy: 81.43%\n",
      "Epoch 47. Training loss: 0.322. Validation loss: 0.354. Validation accuracy: 81.43%\n",
      "Epoch 48. Training loss: 0.321. Validation loss: 0.353. Validation accuracy: 81.43%\n",
      "Epoch 49. Training loss: 0.321. Validation loss: 0.353. Validation accuracy: 81.43%\n",
      "Epoch 50. Training loss: 0.320. Validation loss: 0.353. Validation accuracy: 81.43%\n",
      "Epoch 51. Training loss: 0.320. Validation loss: 0.353. Validation accuracy: 81.43%\n",
      "Epoch 52. Training loss: 0.319. Validation loss: 0.353. Validation accuracy: 81.43%\n",
      "Epoch 53. Training loss: 0.319. Validation loss: 0.353. Validation accuracy: 81.43%\n",
      "Epoch 54. Training loss: 0.319. Validation loss: 0.352. Validation accuracy: 81.43%\n",
      "Epoch 55. Training loss: 0.318. Validation loss: 0.352. Validation accuracy: 81.43%\n",
      "Epoch 56. Training loss: 0.318. Validation loss: 0.352. Validation accuracy: 81.43%\n",
      "Epoch 57. Training loss: 0.318. Validation loss: 0.352. Validation accuracy: 81.43%\n",
      "Epoch 58. Training loss: 0.317. Validation loss: 0.352. Validation accuracy: 81.43%\n",
      "Epoch 59. Training loss: 0.317. Validation loss: 0.352. Validation accuracy: 81.43%\n",
      "End of training.\n"
     ]
    }
   ],
   "source": [
    "#loop for epochs\n",
    "for epoch_counter in range(max_epochs):\n",
    "    \n",
    "    #Set eopch los to a float '0'\n",
    "    curr_epoch_loss = 0.\n",
    "    \n",
    "    #Iterate over training data by using he __next__ method\n",
    "    for input_batch, target_batch in train_data:\n",
    "        _, batch_loss = sess.run([optimize, mean_loss], \n",
    "            feed_dict={inputs: input_batch, targets: target_batch})\n",
    "        \n",
    "        #Record the batch loss into the current epoch loss\n",
    "        curr_epoch_loss += batch_loss\n",
    "     \n",
    "    #Calculate the mean curr_epoch_loss\n",
    "    curr_epoch_loss /= train_data.batch_count\n",
    "    \n",
    "    #Set validation loss and accuracy for the epoch to zero\n",
    "    validation_loss = 0.\n",
    "    validation_accuracy = 0.\n",
    "    \n",
    "    #Forward propagate the validation set\n",
    "    for input_batch, target_batch in validation_data:\n",
    "        validation_loss, validation_accuracy= sess.run([mean_loss, accuracy], \n",
    "        feed_dict={inputs: input_batch, targets: target_batch})   \n",
    "        \n",
    "    print('Epoch '+str(epoch_counter+1)+\n",
    "          '. Training loss: {0:.3f}'.format(curr_epoch_loss)+\n",
    "          '. Validation loss: {0:.3f}'.format(validation_loss)+\n",
    "          '. Validation accuracy: {0:.2f}'.format(validation_accuracy * 100.)+'%')\n",
    "\n",
    "\n",
    "    if validation_loss > prev_validation_loss:\n",
    "        break\n",
    "        \n",
    "    prev_validation_loss = validation_loss\n",
    "    \n",
    "print('End of training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 83.93%\n"
     ]
    }
   ],
   "source": [
    "#Load test subset\n",
    "test_data = AudiobooksDataReader('test')\n",
    "\n",
    "for input_batch, target_batch in test_data:\n",
    "    test_accuracy  = sess.run([accuracy],\n",
    "    feed_dict={inputs: input_batch, targets:target_batch})\n",
    "\n",
    "test_accuracy_percent = test_accuracy[0]*100\n",
    "print('Test accuracy: {0:.2f}'.format(test_accuracy_percent)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deep neural network can predict behaviour 4 of 5 clients, so it's a good achievement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a LGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data and preprocess as before\n",
    "path_data = 'D:\\\\Dokumenty\\\\Piotr\\\\PROJEKTY\\\\audiobook shop\\\\audiobooks_data_new.csv'\n",
    "raw_data = pd.read_csv(path_data,delimiter=',',header=None,names=columns)\n",
    "raw_data['review'].fillna(value=reviews_avg,inplace=True)\n",
    "raw_data.insert(loc=10,column='completion*last_visit_since_purchase',value=raw_data['completion']*raw_data['last_visit_since_purchase'])\n",
    "\n",
    "raw_data.to_csv('raw_data.csv',index=False, header=False)\n",
    "path_csv= 'raw_data.csv'\n",
    "raw_csv_data = np.loadtxt(path_csv,delimiter=\",\")\n",
    "\n",
    "raw_inputs = raw_csv_data[:,1:-1]\n",
    "raw_targets = raw_csv_data[:,-1]\n",
    "std_inputs = preprocessing.scale(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data:\n",
    "#Test set\n",
    "x, x_test, y, y_test = train_test_split(std_inputs,raw_targets,test_size=0.2,  random_state=12345)\n",
    "#Train and valid sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x,y,test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build model\n",
    "d_train = lgb.Dataset(x_train, y_train)\n",
    "d_valid = lgb.Dataset(x_valid, y_valid)\n",
    "d_test = lgb.Dataset(x_test, y_test)\n",
    "\n",
    "watchlist = [d_train, d_valid, d_test]\n",
    "\n",
    "params = {\"metric\" : [\"auc\", \"binary_error\"], \"apllication\" : \"binary\", \"num_leaves\" : [220], \n",
    "         \"min_data_in_leaf\" : [8]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.947898\ttraining's binary_error: 0.159645\tvalid_1's auc: 0.889374\tvalid_1's binary_error: 0.150515\tvalid_2's auc: 0.876971\tvalid_2's binary_error: 0.164714\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\ttraining's auc: 0.949118\ttraining's binary_error: 0.159645\tvalid_1's auc: 0.89234\tvalid_1's binary_error: 0.150515\tvalid_2's auc: 0.876407\tvalid_2's binary_error: 0.164714\n",
      "[3]\ttraining's auc: 0.94973\ttraining's binary_error: 0.159645\tvalid_1's auc: 0.893078\tvalid_1's binary_error: 0.150515\tvalid_2's auc: 0.876287\tvalid_2's binary_error: 0.164714\n",
      "[4]\ttraining's auc: 0.950736\ttraining's binary_error: 0.159645\tvalid_1's auc: 0.895889\tvalid_1's binary_error: 0.150515\tvalid_2's auc: 0.882951\tvalid_2's binary_error: 0.164714\n",
      "[5]\ttraining's auc: 0.95108\ttraining's binary_error: 0.0959763\tvalid_1's auc: 0.89685\tvalid_1's binary_error: 0.086972\tvalid_2's auc: 0.883397\tvalid_2's binary_error: 0.102946\n",
      "[6]\ttraining's auc: 0.952262\ttraining's binary_error: 0.0880473\tvalid_1's auc: 0.89444\tvalid_1's binary_error: 0.0834221\tvalid_2's auc: 0.881992\tvalid_2's binary_error: 0.0972666\n",
      "[7]\ttraining's auc: 0.953148\ttraining's binary_error: 0.0849704\tvalid_1's auc: 0.896073\tvalid_1's binary_error: 0.0805822\tvalid_2's auc: 0.884235\tvalid_2's binary_error: 0.0947817\n",
      "[8]\ttraining's auc: 0.954026\ttraining's binary_error: 0.0840237\tvalid_1's auc: 0.899369\tvalid_1's binary_error: 0.0798722\tvalid_2's auc: 0.88414\tvalid_2's binary_error: 0.0940717\n",
      "[9]\ttraining's auc: 0.954558\ttraining's binary_error: 0.080355\tvalid_1's auc: 0.89998\tvalid_1's binary_error: 0.0777423\tvalid_2's auc: 0.883665\tvalid_2's binary_error: 0.0944267\n",
      "[10]\ttraining's auc: 0.95501\ttraining's binary_error: 0.0782249\tvalid_1's auc: 0.900517\tvalid_1's binary_error: 0.0788072\tvalid_2's auc: 0.890608\tvalid_2's binary_error: 0.0954917\n",
      "[11]\ttraining's auc: 0.955657\ttraining's binary_error: 0.076568\tvalid_1's auc: 0.901437\tvalid_1's binary_error: 0.0812922\tvalid_2's auc: 0.890385\tvalid_2's binary_error: 0.0958466\n",
      "[12]\ttraining's auc: 0.956455\ttraining's binary_error: 0.0746746\tvalid_1's auc: 0.901095\tvalid_1's binary_error: 0.0795172\tvalid_2's auc: 0.889237\tvalid_2's binary_error: 0.0986865\n",
      "[13]\ttraining's auc: 0.956702\ttraining's binary_error: 0.0726627\tvalid_1's auc: 0.901268\tvalid_1's binary_error: 0.0795172\tvalid_2's auc: 0.888083\tvalid_2's binary_error: 0.0979766\n",
      "[14]\ttraining's auc: 0.957143\ttraining's binary_error: 0.0705325\tvalid_1's auc: 0.898416\tvalid_1's binary_error: 0.0802272\tvalid_2's auc: 0.888484\tvalid_2's binary_error: 0.0983316\n",
      "[15]\ttraining's auc: 0.957637\ttraining's binary_error: 0.0684024\tvalid_1's auc: 0.897971\tvalid_1's binary_error: 0.0805822\tvalid_2's auc: 0.889582\tvalid_2's binary_error: 0.0997515\n",
      "[16]\ttraining's auc: 0.957975\ttraining's binary_error: 0.0672189\tvalid_1's auc: 0.901216\tvalid_1's binary_error: 0.0823571\tvalid_2's auc: 0.888944\tvalid_2's binary_error: 0.100461\n",
      "[17]\ttraining's auc: 0.958365\ttraining's binary_error: 0.0659172\tvalid_1's auc: 0.901366\tvalid_1's binary_error: 0.0827121\tvalid_2's auc: 0.889604\tvalid_2's binary_error: 0.0997515\n",
      "[18]\ttraining's auc: 0.958683\ttraining's binary_error: 0.0654438\tvalid_1's auc: 0.897994\tvalid_1's binary_error: 0.0827121\tvalid_2's auc: 0.888759\tvalid_2's binary_error: 0.0986865\n",
      "[19]\ttraining's auc: 0.958942\ttraining's binary_error: 0.0640237\tvalid_1's auc: 0.900018\tvalid_1's binary_error: 0.0834221\tvalid_2's auc: 0.890341\tvalid_2's binary_error: 0.100106\n",
      "[20]\ttraining's auc: 0.95933\ttraining's binary_error: 0.0618935\tvalid_1's auc: 0.903806\tvalid_1's binary_error: 0.0841321\tvalid_2's auc: 0.886504\tvalid_2's binary_error: 0.101526\n",
      "[21]\ttraining's auc: 0.959784\ttraining's binary_error: 0.0607101\tvalid_1's auc: 0.902694\tvalid_1's binary_error: 0.0841321\tvalid_2's auc: 0.888318\tvalid_2's binary_error: 0.101881\n",
      "[22]\ttraining's auc: 0.960173\ttraining's binary_error: 0.0592899\tvalid_1's auc: 0.902386\tvalid_1's binary_error: 0.084842\tvalid_2's auc: 0.883882\tvalid_2's binary_error: 0.102946\n",
      "[23]\ttraining's auc: 0.96055\ttraining's binary_error: 0.0586982\tvalid_1's auc: 0.899689\tvalid_1's binary_error: 0.0841321\tvalid_2's auc: 0.886118\tvalid_2's binary_error: 0.104011\n",
      "[24]\ttraining's auc: 0.960849\ttraining's binary_error: 0.0579882\tvalid_1's auc: 0.898614\tvalid_1's binary_error: 0.0834221\tvalid_2's auc: 0.883962\tvalid_2's binary_error: 0.104366\n",
      "[25]\ttraining's auc: 0.96109\ttraining's binary_error: 0.0569231\tvalid_1's auc: 0.896806\tvalid_1's binary_error: 0.084487\tvalid_2's auc: 0.881198\tvalid_2's binary_error: 0.104721\n",
      "[26]\ttraining's auc: 0.961386\ttraining's binary_error: 0.0570414\tvalid_1's auc: 0.899336\tvalid_1's binary_error: 0.084842\tvalid_2's auc: 0.883692\tvalid_2's binary_error: 0.104721\n",
      "[27]\ttraining's auc: 0.961525\ttraining's binary_error: 0.0566864\tvalid_1's auc: 0.899095\tvalid_1's binary_error: 0.084487\tvalid_2's auc: 0.882779\tvalid_2's binary_error: 0.105076\n",
      "[28]\ttraining's auc: 0.961798\ttraining's binary_error: 0.056568\tvalid_1's auc: 0.897535\tvalid_1's binary_error: 0.084842\tvalid_2's auc: 0.881828\tvalid_2's binary_error: 0.106141\n",
      "[29]\ttraining's auc: 0.962044\ttraining's binary_error: 0.0559763\tvalid_1's auc: 0.899028\tvalid_1's binary_error: 0.084842\tvalid_2's auc: 0.881362\tvalid_2's binary_error: 0.105431\n",
      "[30]\ttraining's auc: 0.962255\ttraining's binary_error: 0.0552663\tvalid_1's auc: 0.898421\tvalid_1's binary_error: 0.084842\tvalid_2's auc: 0.881423\tvalid_2's binary_error: 0.105076\n",
      "[31]\ttraining's auc: 0.962497\ttraining's binary_error: 0.0551479\tvalid_1's auc: 0.899678\tvalid_1's binary_error: 0.084842\tvalid_2's auc: 0.880871\tvalid_2's binary_error: 0.106141\n",
      "[32]\ttraining's auc: 0.962769\ttraining's binary_error: 0.0547929\tvalid_1's auc: 0.897782\tvalid_1's binary_error: 0.085907\tvalid_2's auc: 0.880422\tvalid_2's binary_error: 0.106851\n",
      "[33]\ttraining's auc: 0.963084\ttraining's binary_error: 0.0539645\tvalid_1's auc: 0.896635\tvalid_1's binary_error: 0.085552\tvalid_2's auc: 0.88364\tvalid_2's binary_error: 0.107916\n",
      "[34]\ttraining's auc: 0.963232\ttraining's binary_error: 0.0534911\tvalid_1's auc: 0.897877\tvalid_1's binary_error: 0.084842\tvalid_2's auc: 0.882831\tvalid_2's binary_error: 0.107916\n",
      "[35]\ttraining's auc: 0.96344\ttraining's binary_error: 0.0533728\tvalid_1's auc: 0.897419\tvalid_1's binary_error: 0.085197\tvalid_2's auc: 0.882889\tvalid_2's binary_error: 0.107206\n",
      "[36]\ttraining's auc: 0.963616\ttraining's binary_error: 0.0530178\tvalid_1's auc: 0.897606\tvalid_1's binary_error: 0.085552\tvalid_2's auc: 0.882214\tvalid_2's binary_error: 0.107561\n",
      "[37]\ttraining's auc: 0.963804\ttraining's binary_error: 0.0521893\tvalid_1's auc: 0.894981\tvalid_1's binary_error: 0.085907\tvalid_2's auc: 0.883099\tvalid_2's binary_error: 0.107561\n",
      "[38]\ttraining's auc: 0.963985\ttraining's binary_error: 0.052071\tvalid_1's auc: 0.894828\tvalid_1's binary_error: 0.0876819\tvalid_2's auc: 0.884679\tvalid_2's binary_error: 0.106496\n",
      "[39]\ttraining's auc: 0.964162\ttraining's binary_error: 0.0510059\tvalid_1's auc: 0.894233\tvalid_1's binary_error: 0.0880369\tvalid_2's auc: 0.883733\tvalid_2's binary_error: 0.105431\n",
      "[40]\ttraining's auc: 0.964342\ttraining's binary_error: 0.0512426\tvalid_1's auc: 0.894436\tvalid_1's binary_error: 0.0887469\tvalid_2's auc: 0.881539\tvalid_2's binary_error: 0.105076\n",
      "[41]\ttraining's auc: 0.964436\ttraining's binary_error: 0.0501775\tvalid_1's auc: 0.893322\tvalid_1's binary_error: 0.0894569\tvalid_2's auc: 0.881038\tvalid_2's binary_error: 0.105076\n",
      "[42]\ttraining's auc: 0.964608\ttraining's binary_error: 0.0504142\tvalid_1's auc: 0.892987\tvalid_1's binary_error: 0.0894569\tvalid_2's auc: 0.88098\tvalid_2's binary_error: 0.105786\n",
      "[43]\ttraining's auc: 0.964684\ttraining's binary_error: 0.0502959\tvalid_1's auc: 0.893218\tvalid_1's binary_error: 0.0894569\tvalid_2's auc: 0.880913\tvalid_2's binary_error: 0.104721\n",
      "[44]\ttraining's auc: 0.964902\ttraining's binary_error: 0.0500592\tvalid_1's auc: 0.89148\tvalid_1's binary_error: 0.0883919\tvalid_2's auc: 0.880932\tvalid_2's binary_error: 0.105431\n",
      "[45]\ttraining's auc: 0.965023\ttraining's binary_error: 0.0500592\tvalid_1's auc: 0.891533\tvalid_1's binary_error: 0.0880369\tvalid_2's auc: 0.878905\tvalid_2's binary_error: 0.104721\n",
      "[46]\ttraining's auc: 0.965209\ttraining's binary_error: 0.0497041\tvalid_1's auc: 0.888921\tvalid_1's binary_error: 0.0883919\tvalid_2's auc: 0.878543\tvalid_2's binary_error: 0.104721\n",
      "[47]\ttraining's auc: 0.965387\ttraining's binary_error: 0.0495858\tvalid_1's auc: 0.888795\tvalid_1's binary_error: 0.0887469\tvalid_2's auc: 0.876359\tvalid_2's binary_error: 0.104721\n",
      "[48]\ttraining's auc: 0.965513\ttraining's binary_error: 0.0494675\tvalid_1's auc: 0.888245\tvalid_1's binary_error: 0.0894569\tvalid_2's auc: 0.878575\tvalid_2's binary_error: 0.106141\n",
      "[49]\ttraining's auc: 0.965694\ttraining's binary_error: 0.0488757\tvalid_1's auc: 0.887764\tvalid_1's binary_error: 0.0891019\tvalid_2's auc: 0.876737\tvalid_2's binary_error: 0.105786\n",
      "[50]\ttraining's auc: 0.96582\ttraining's binary_error: 0.0485207\tvalid_1's auc: 0.887777\tvalid_1's binary_error: 0.0891019\tvalid_2's auc: 0.875461\tvalid_2's binary_error: 0.105431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51]\ttraining's auc: 0.965955\ttraining's binary_error: 0.0484024\tvalid_1's auc: 0.88832\tvalid_1's binary_error: 0.0891019\tvalid_2's auc: 0.87474\tvalid_2's binary_error: 0.105431\n",
      "[52]\ttraining's auc: 0.966113\ttraining's binary_error: 0.0481657\tvalid_1's auc: 0.887665\tvalid_1's binary_error: 0.0887469\tvalid_2's auc: 0.873526\tvalid_2's binary_error: 0.105786\n",
      "[53]\ttraining's auc: 0.966255\ttraining's binary_error: 0.0480473\tvalid_1's auc: 0.886682\tvalid_1's binary_error: 0.0880369\tvalid_2's auc: 0.87459\tvalid_2's binary_error: 0.105076\n",
      "[54]\ttraining's auc: 0.966373\ttraining's binary_error: 0.0478107\tvalid_1's auc: 0.886745\tvalid_1's binary_error: 0.086972\tvalid_2's auc: 0.874105\tvalid_2's binary_error: 0.105076\n",
      "[55]\ttraining's auc: 0.966495\ttraining's binary_error: 0.0478107\tvalid_1's auc: 0.88684\tvalid_1's binary_error: 0.0873269\tvalid_2's auc: 0.873093\tvalid_2's binary_error: 0.105431\n",
      "[56]\ttraining's auc: 0.966595\ttraining's binary_error: 0.0478107\tvalid_1's auc: 0.886533\tvalid_1's binary_error: 0.086617\tvalid_2's auc: 0.872889\tvalid_2's binary_error: 0.106141\n",
      "[57]\ttraining's auc: 0.966799\ttraining's binary_error: 0.0474556\tvalid_1's auc: 0.887025\tvalid_1's binary_error: 0.0883919\tvalid_2's auc: 0.871801\tvalid_2's binary_error: 0.107561\n",
      "[58]\ttraining's auc: 0.966886\ttraining's binary_error: 0.0473373\tvalid_1's auc: 0.887528\tvalid_1's binary_error: 0.086972\tvalid_2's auc: 0.872099\tvalid_2's binary_error: 0.107206\n",
      "[59]\ttraining's auc: 0.966996\ttraining's binary_error: 0.0472189\tvalid_1's auc: 0.887126\tvalid_1's binary_error: 0.0876819\tvalid_2's auc: 0.872286\tvalid_2's binary_error: 0.106851\n",
      "[60]\ttraining's auc: 0.967077\ttraining's binary_error: 0.0469822\tvalid_1's auc: 0.887375\tvalid_1's binary_error: 0.0873269\tvalid_2's auc: 0.872002\tvalid_2's binary_error: 0.107561\n",
      "[61]\ttraining's auc: 0.967181\ttraining's binary_error: 0.0469822\tvalid_1's auc: 0.886585\tvalid_1's binary_error: 0.0876819\tvalid_2's auc: 0.871321\tvalid_2's binary_error: 0.107206\n",
      "[62]\ttraining's auc: 0.967246\ttraining's binary_error: 0.0466272\tvalid_1's auc: 0.885789\tvalid_1's binary_error: 0.0880369\tvalid_2's auc: 0.871038\tvalid_2's binary_error: 0.106851\n",
      "[63]\ttraining's auc: 0.967343\ttraining's binary_error: 0.0466272\tvalid_1's auc: 0.884929\tvalid_1's binary_error: 0.0880369\tvalid_2's auc: 0.870038\tvalid_2's binary_error: 0.107206\n",
      "[64]\ttraining's auc: 0.967451\ttraining's binary_error: 0.0465089\tvalid_1's auc: 0.884626\tvalid_1's binary_error: 0.0876819\tvalid_2's auc: 0.869706\tvalid_2's binary_error: 0.106851\n",
      "[65]\ttraining's auc: 0.967565\ttraining's binary_error: 0.0462722\tvalid_1's auc: 0.884307\tvalid_1's binary_error: 0.0883919\tvalid_2's auc: 0.86941\tvalid_2's binary_error: 0.106496\n",
      "[66]\ttraining's auc: 0.96764\ttraining's binary_error: 0.0460355\tvalid_1's auc: 0.88449\tvalid_1's binary_error: 0.0883919\tvalid_2's auc: 0.86878\tvalid_2's binary_error: 0.106496\n",
      "[67]\ttraining's auc: 0.967756\ttraining's binary_error: 0.0455621\tvalid_1's auc: 0.884494\tvalid_1's binary_error: 0.0887469\tvalid_2's auc: 0.86813\tvalid_2's binary_error: 0.106141\n",
      "[68]\ttraining's auc: 0.96783\ttraining's binary_error: 0.0455621\tvalid_1's auc: 0.883967\tvalid_1's binary_error: 0.0883919\tvalid_2's auc: 0.868327\tvalid_2's binary_error: 0.106496\n",
      "[69]\ttraining's auc: 0.967899\ttraining's binary_error: 0.0456805\tvalid_1's auc: 0.883284\tvalid_1's binary_error: 0.0883919\tvalid_2's auc: 0.868048\tvalid_2's binary_error: 0.106496\n",
      "[70]\ttraining's auc: 0.967966\ttraining's binary_error: 0.0455621\tvalid_1's auc: 0.882687\tvalid_1's binary_error: 0.0880369\tvalid_2's auc: 0.867818\tvalid_2's binary_error: 0.106141\n",
      "[71]\ttraining's auc: 0.968022\ttraining's binary_error: 0.0454438\tvalid_1's auc: 0.883429\tvalid_1's binary_error: 0.0880369\tvalid_2's auc: 0.868047\tvalid_2's binary_error: 0.106496\n",
      "[72]\ttraining's auc: 0.968135\ttraining's binary_error: 0.0453254\tvalid_1's auc: 0.883807\tvalid_1's binary_error: 0.0876819\tvalid_2's auc: 0.867772\tvalid_2's binary_error: 0.106851\n",
      "[73]\ttraining's auc: 0.968205\ttraining's binary_error: 0.0453254\tvalid_1's auc: 0.883919\tvalid_1's binary_error: 0.0887469\tvalid_2's auc: 0.8675\tvalid_2's binary_error: 0.107206\n",
      "[74]\ttraining's auc: 0.968258\ttraining's binary_error: 0.0452071\tvalid_1's auc: 0.883543\tvalid_1's binary_error: 0.0887469\tvalid_2's auc: 0.867374\tvalid_2's binary_error: 0.106851\n",
      "[75]\ttraining's auc: 0.968335\ttraining's binary_error: 0.0450888\tvalid_1's auc: 0.883501\tvalid_1's binary_error: 0.0887469\tvalid_2's auc: 0.867232\tvalid_2's binary_error: 0.107206\n",
      "[76]\ttraining's auc: 0.968409\ttraining's binary_error: 0.0450888\tvalid_1's auc: 0.883193\tvalid_1's binary_error: 0.0887469\tvalid_2's auc: 0.867063\tvalid_2's binary_error: 0.106851\n",
      "[77]\ttraining's auc: 0.968467\ttraining's binary_error: 0.0449704\tvalid_1's auc: 0.883185\tvalid_1's binary_error: 0.0891019\tvalid_2's auc: 0.86665\tvalid_2's binary_error: 0.106851\n",
      "[78]\ttraining's auc: 0.968568\ttraining's binary_error: 0.0449704\tvalid_1's auc: 0.882891\tvalid_1's binary_error: 0.0887469\tvalid_2's auc: 0.865872\tvalid_2's binary_error: 0.106851\n",
      "[79]\ttraining's auc: 0.968612\ttraining's binary_error: 0.0448521\tvalid_1's auc: 0.882128\tvalid_1's binary_error: 0.0891019\tvalid_2's auc: 0.86602\tvalid_2's binary_error: 0.106851\n",
      "[80]\ttraining's auc: 0.968668\ttraining's binary_error: 0.0448521\tvalid_1's auc: 0.88211\tvalid_1's binary_error: 0.0894569\tvalid_2's auc: 0.866376\tvalid_2's binary_error: 0.106496\n",
      "[81]\ttraining's auc: 0.968722\ttraining's binary_error: 0.0447337\tvalid_1's auc: 0.881831\tvalid_1's binary_error: 0.0898119\tvalid_2's auc: 0.867008\tvalid_2's binary_error: 0.106496\n",
      "[82]\ttraining's auc: 0.968784\ttraining's binary_error: 0.044497\tvalid_1's auc: 0.882647\tvalid_1's binary_error: 0.0912318\tvalid_2's auc: 0.86618\tvalid_2's binary_error: 0.106851\n",
      "[83]\ttraining's auc: 0.968848\ttraining's binary_error: 0.0442604\tvalid_1's auc: 0.882688\tvalid_1's binary_error: 0.0915868\tvalid_2's auc: 0.865873\tvalid_2's binary_error: 0.106851\n",
      "[84]\ttraining's auc: 0.968928\ttraining's binary_error: 0.0442604\tvalid_1's auc: 0.882962\tvalid_1's binary_error: 0.0926518\tvalid_2's auc: 0.8657\tvalid_2's binary_error: 0.106851\n",
      "[85]\ttraining's auc: 0.968999\ttraining's binary_error: 0.0442604\tvalid_1's auc: 0.882844\tvalid_1's binary_error: 0.0926518\tvalid_2's auc: 0.8656\tvalid_2's binary_error: 0.106851\n",
      "[86]\ttraining's auc: 0.969016\ttraining's binary_error: 0.0442604\tvalid_1's auc: 0.88296\tvalid_1's binary_error: 0.0926518\tvalid_2's auc: 0.865169\tvalid_2's binary_error: 0.106851\n",
      "[87]\ttraining's auc: 0.969062\ttraining's binary_error: 0.044142\tvalid_1's auc: 0.882733\tvalid_1's binary_error: 0.0926518\tvalid_2's auc: 0.865471\tvalid_2's binary_error: 0.107206\n",
      "[88]\ttraining's auc: 0.969113\ttraining's binary_error: 0.0440237\tvalid_1's auc: 0.883072\tvalid_1's binary_error: 0.0922968\tvalid_2's auc: 0.865543\tvalid_2's binary_error: 0.107916\n",
      "[89]\ttraining's auc: 0.969163\ttraining's binary_error: 0.043787\tvalid_1's auc: 0.883318\tvalid_1's binary_error: 0.0922968\tvalid_2's auc: 0.865453\tvalid_2's binary_error: 0.107916\n",
      "[90]\ttraining's auc: 0.969233\ttraining's binary_error: 0.043787\tvalid_1's auc: 0.883252\tvalid_1's binary_error: 0.0930067\tvalid_2's auc: 0.865242\tvalid_2's binary_error: 0.107916\n",
      "[91]\ttraining's auc: 0.969319\ttraining's binary_error: 0.0436686\tvalid_1's auc: 0.883038\tvalid_1's binary_error: 0.0919418\tvalid_2's auc: 0.86506\tvalid_2's binary_error: 0.107561\n",
      "[92]\ttraining's auc: 0.969376\ttraining's binary_error: 0.0435503\tvalid_1's auc: 0.883205\tvalid_1's binary_error: 0.0915868\tvalid_2's auc: 0.864659\tvalid_2's binary_error: 0.107561\n",
      "[93]\ttraining's auc: 0.96946\ttraining's binary_error: 0.0433136\tvalid_1's auc: 0.883619\tvalid_1's binary_error: 0.0919418\tvalid_2's auc: 0.86482\tvalid_2's binary_error: 0.107561\n",
      "[94]\ttraining's auc: 0.969489\ttraining's binary_error: 0.0433136\tvalid_1's auc: 0.883023\tvalid_1's binary_error: 0.0919418\tvalid_2's auc: 0.86448\tvalid_2's binary_error: 0.107561\n",
      "[95]\ttraining's auc: 0.969584\ttraining's binary_error: 0.0429586\tvalid_1's auc: 0.882955\tvalid_1's binary_error: 0.0922968\tvalid_2's auc: 0.864069\tvalid_2's binary_error: 0.107561\n",
      "[96]\ttraining's auc: 0.969625\ttraining's binary_error: 0.0430769\tvalid_1's auc: 0.883257\tvalid_1's binary_error: 0.0926518\tvalid_2's auc: 0.864252\tvalid_2's binary_error: 0.107916\n",
      "[97]\ttraining's auc: 0.969679\ttraining's binary_error: 0.0428402\tvalid_1's auc: 0.882458\tvalid_1's binary_error: 0.0926518\tvalid_2's auc: 0.863907\tvalid_2's binary_error: 0.108626\n",
      "[98]\ttraining's auc: 0.969719\ttraining's binary_error: 0.0428402\tvalid_1's auc: 0.882151\tvalid_1's binary_error: 0.0930067\tvalid_2's auc: 0.863711\tvalid_2's binary_error: 0.108271\n",
      "[99]\ttraining's auc: 0.969787\ttraining's binary_error: 0.0427219\tvalid_1's auc: 0.881954\tvalid_1's binary_error: 0.0930067\tvalid_2's auc: 0.863304\tvalid_2's binary_error: 0.108271\n",
      "[100]\ttraining's auc: 0.969824\ttraining's binary_error: 0.0427219\tvalid_1's auc: 0.881794\tvalid_1's binary_error: 0.0930067\tvalid_2's auc: 0.863145\tvalid_2's binary_error: 0.108626\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.969824\ttraining's binary_error: 0.0427219\tvalid_1's auc: 0.881794\tvalid_1's binary_error: 0.0930067\tvalid_2's auc: 0.863145\tvalid_2's binary_error: 0.108626\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "model = lgb.train(params, train_set= d_train, num_boost_round=100, valid_sets= watchlist, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'training': {'auc': 0.9698240436176155,\n",
       "              'binary_error': 0.04272189349112426},\n",
       "             'valid_1': {'auc': 0.8817935961018379,\n",
       "              'binary_error': 0.09300674476393327},\n",
       "             'valid_2': {'auc': 0.8631451778360714,\n",
       "              'binary_error': 0.10862619808306709}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC score on second valid (test) set is about 85-87% and binarry error is about 10-11%, so it's a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plot shows how much important was each variable used in lgbm algorithm:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEWCAYAAADVW8iBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a0d0bd81d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Feature importance\n",
    "lgb.plot_importance(model)\n",
    "print(\"\\nPlot shows how much important was each variable used in lgbm algorithm:\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_avg</th>\n",
       "      <th>len_overall</th>\n",
       "      <th>price_avg</th>\n",
       "      <th>price_overall</th>\n",
       "      <th>if_review</th>\n",
       "      <th>review</th>\n",
       "      <th>completion</th>\n",
       "      <th>total_listen</th>\n",
       "      <th>support_req</th>\n",
       "      <th>completion*last_visit_since_purchase</th>\n",
       "      <th>last_visit_since_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>19.73</td>\n",
       "      <td>19.73</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1603.8</td>\n",
       "      <td>5</td>\n",
       "      <td>91.08</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.0</td>\n",
       "      <td>324</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1404.0</td>\n",
       "      <td>2808</td>\n",
       "      <td>6.67</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1188.0</td>\n",
       "      <td>1188</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   len_avg  len_overall  price_avg  price_overall  if_review  review  \\\n",
       "0   1620.0         1620      19.73          19.73          1    10.0   \n",
       "1   1620.0         1620       5.33           5.33          1     2.0   \n",
       "2    324.0          324       5.33           5.33          1     2.0   \n",
       "3   1404.0         2808       6.67          13.33          1     3.0   \n",
       "4   1188.0         1188       5.33           5.33          1     4.0   \n",
       "\n",
       "   completion  total_listen  support_req  \\\n",
       "0        0.99        1603.8            5   \n",
       "1        0.00           0.0            0   \n",
       "2        0.00           0.0            0   \n",
       "3        0.00           0.0            1   \n",
       "4        0.00           0.0            0   \n",
       "\n",
       "   completion*last_visit_since_purchase  last_visit_since_purchase  \n",
       "0                                 91.08                         92  \n",
       "1                                  0.00                        145  \n",
       "2                                  0.00                          0  \n",
       "3                                  0.00                        176  \n",
       "4                                  0.00                        255  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.drop(['ID','targets'],axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most importance columns for algorithm are: last visit since purchase, price_avg and len_avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
